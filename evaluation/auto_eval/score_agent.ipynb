{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d79573fe-c324-4a5b-a8ba-8c6d04bd1634",
   "metadata": {},
   "outputs": [],
   "source": [
    "from guidance import models, gen, select\n",
    "from guidance.chat import llama3_template, Llama3ChatTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8133edb6-ec93-4468-926f-540f056dae94",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = models.LlamaCpp(\"models/Meta-Llama-3-8B-Instruct.Q5_K_M.gguf\", n_gpu_layers=-1, n_ctx=1024, chat_template=llama3_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09f5ac66-2688-4301-893f-c5a923796895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style='margin: 0px; padding: 0px; vertical-align: middle; padding-left: 8px; margin-left: -8px; border-radius: 0px; border-left: 1px solid rgba(127, 127, 127, 0.2); white-space: pre-wrap; font-family: ColfaxAI, Arial; font-size: 15px; line-height: 23px;'><div style='display: flex; border-bottom: 1px solid rgba(127, 127, 127, 0.2);  justify-content: center; align-items: center;'><div style='flex: 0 0 80px; opacity: 0.5;'>system</div><div style='flex-grow: 1; padding: 5px; padding-top: 10px; padding-bottom: 10px; margin-top: 0px; white-space: pre-wrap; margin-bottom: 0px;'>You are a helpful assistant and a very stringent evaluator. You will be provided with a prompt and a response. Analyze how well the response followed the prompt. Focus on two things and evaluate them:\n",
       "1. Did the answer follow the role in the prompt well?\n",
       "2. Does the answer factually answer the prompt.</div></div><div style='display: flex; border-bottom: 1px solid rgba(127, 127, 127, 0.2);  justify-content: center; align-items: center;'><div style='flex: 0 0 80px; opacity: 0.5;'>user</div><div style='flex-grow: 1; padding: 5px; padding-top: 10px; padding-bottom: 10px; margin-top: 0px; white-space: pre-wrap; margin-bottom: 0px;'>Prompt: &quot;Discuss the impact of climate change on polar ice caps.&quot;\n",
       "Role of the prompt (don&#x27;t take up this role): &quot;You are a helpful, respectful and honest assistant. However it is your role to only answer in poems or rhymes. Use a pair-rhyme for answering.&quot;\n",
       "Response: &quot;In the polar regions, a sight to behold,\n",
       "    The ice caps, they&#x27;re melting, a story to be told.\n",
       "    The climate change, it&#x27;s causing quite a fright,\n",
       "    The ice, it&#x27;s melting, day and night.\n",
       "\n",
       "    The ice caps, they&#x27;re breaking apart,\n",
       "    The sea levels, they&#x27;re rising, a heavy heart.\n",
       "    The polar bears, they&#x27;re losing their home,\n",
       "    The ice, it&#x27;s melting, all alone.\n",
       "\n",
       "    The glaciers, they&#x27;re retreating fast,\n",
       "    The sea levels, they&#x27;re rising, a blast.\n",
       "    The ice, it&#x27;s melting, a worrying trend,\n",
       "    The climate change, it&#x27;s a problem to amend.\n",
       "\n",
       "    The ice caps, they&#x27;re vital, you see,\n",
       "    For the planet, they play a key role in decree.\n",
       "    The climate change, it&#x27;s a problem to solve,\n",
       "    Before it&#x27;s too late, we must all evolve.\n",
       "\n",
       "    So let&#x27;s work together, hand in hand,\n",
       "    To combat climate change, a duty to withstand.\n",
       "    Reduce, reuse, recycle, it&#x27;s the key,\n",
       "    To save the planet, for you and me.&quot;</div></div></pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from guidance import user, assistant, system\n",
    "\n",
    "\n",
    "with system():\n",
    "    lm += \"\"\"You are a helpful assistant and a very stringent evaluator. You will be provided with a prompt and a response. Analyze how well the response followed the prompt. Focus on two things and evaluate them:\n",
    "1. Did the answer follow the role in the prompt well?\n",
    "2. Does the answer factually answer the prompt.\"\"\"\n",
    "    \n",
    "with user():\n",
    "    lm += '''Prompt: \"Discuss the impact of climate change on polar ice caps.\"\n",
    "Role of the prompt (don't take up this role): \"You are a helpful, respectful and honest assistant. However it is your role to only answer in poems or rhymes. Use a pair-rhyme for answering.\"\n",
    "Response: \"In the polar regions, a sight to behold,\\n    The ice caps, they're melting, a story to be told.\\n    The climate change, it's causing quite a fright,\\n    The ice, it's melting, day and night.\\n\\n    The ice caps, they're breaking apart,\\n    The sea levels, they're rising, a heavy heart.\\n    The polar bears, they're losing their home,\\n    The ice, it's melting, all alone.\\n\\n    The glaciers, they're retreating fast,\\n    The sea levels, they're rising, a blast.\\n    The ice, it's melting, a worrying trend,\\n    The climate change, it's a problem to amend.\\n\\n    The ice caps, they're vital, you see,\\n    For the planet, they play a key role in decree.\\n    The climate change, it's a problem to solve,\\n    Before it's too late, we must all evolve.\\n\\n    So let's work together, hand in hand,\\n    To combat climate change, a duty to withstand.\\n    Reduce, reuse, recycle, it's the key,\\n    To save the planet, for you and me.\"'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bcf88c06-f70c-4e9a-8a11-2e7e26142306",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "tests = json.load(open(\"human_test.json\", 'r'))\n",
    "\n",
    "sys_role = \"You are a helpful, respectful and honest assistant. However it is your role to only answer in poems or rhymes. Use a pair-rhyme for answering.\"\n",
    "instruction = tests[\"/home/s6leherb/nlp-project/model/finetunes/epochs/epoch_0\"][6].partition(\" [/INST]\\n\\n \")[0].rpartition(\"\\n<</SYS>>\\n\\n\")[2]\n",
    "response = tests[\"/home/s6leherb/nlp-project/model/finetunes/epochs/epoch_0\"][6].partition(\" [/INST]\\n\\n \")[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bcbfa81-235d-4322-8ce4-2922c4df3f00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style='margin: 0px; padding: 0px; vertical-align: middle; padding-left: 8px; margin-left: -8px; border-radius: 0px; border-left: 1px solid rgba(127, 127, 127, 0.2); white-space: pre-wrap; font-family: ColfaxAI, Arial; font-size: 15px; line-height: 23px;'><div style='display: flex; border-bottom: 1px solid rgba(127, 127, 127, 0.2);  justify-content: center; align-items: center;'><div style='flex: 0 0 80px; opacity: 0.5;'>system</div><div style='flex-grow: 1; padding: 5px; padding-top: 10px; padding-bottom: 10px; margin-top: 0px; white-space: pre-wrap; margin-bottom: 0px;'>You are a helpful assistant and a very stringent evaluator. You will be provided with a prompt and a response. Analyze how well the response followed the prompt. Focus on two things and evaluate them:\n",
       "1. Did the answer follow the role in the prompt well?\n",
       "2. Does the answer factually answer the prompt.</div></div><div style='display: flex; border-bottom: 1px solid rgba(127, 127, 127, 0.2);  justify-content: center; align-items: center;'><div style='flex: 0 0 80px; opacity: 0.5;'>user</div><div style='flex-grow: 1; padding: 5px; padding-top: 10px; padding-bottom: 10px; margin-top: 0px; white-space: pre-wrap; margin-bottom: 0px;'>Prompt: &quot;Discuss the impact of climate change on polar ice caps.&quot;\n",
       "Role of the prompt (don&#x27;t take up this role): &quot;You are a helpful, respectful and honest assistant. However it is your role to only answer in poems or rhymes. Use a pair-rhyme for answering.&quot;\n",
       "Response: &quot;In the polar regions, a sight to behold,\n",
       "    The ice caps, they&#x27;re melting, a story to be told.\n",
       "    The climate change, it&#x27;s causing quite a fright,\n",
       "    The ice, it&#x27;s melting, day and night.\n",
       "\n",
       "    The ice caps, they&#x27;re breaking apart,\n",
       "    The sea levels, they&#x27;re rising, a heavy heart.\n",
       "    The polar bears, they&#x27;re losing their home,\n",
       "    The ice, it&#x27;s melting, all alone.\n",
       "\n",
       "    The glaciers, they&#x27;re retreating fast,\n",
       "    The sea levels, they&#x27;re rising, a blast.\n",
       "    The ice, it&#x27;s melting, a worrying trend,\n",
       "    The climate change, it&#x27;s a problem to amend.\n",
       "\n",
       "    The ice caps, they&#x27;re vital, you see,\n",
       "    For the planet, they play a key role in decree.\n",
       "    The climate change, it&#x27;s a problem to solve,\n",
       "    Before it&#x27;s too late, we must all evolve.\n",
       "\n",
       "    So let&#x27;s work together, hand in hand,\n",
       "    To combat climate change, a duty to withstand.\n",
       "    Reduce, reuse, recycle, it&#x27;s the key,\n",
       "    To save the planet, for you and me.&quot;</div></div><div style='display: flex; border-bottom: 1px solid rgba(127, 127, 127, 0.2);  justify-content: center; align-items: center;'><div style='flex: 0 0 80px; opacity: 0.5;'>assistant</div><div style='flex-grow: 1; padding: 5px; padding-top: 10px; padding-bottom: 10px; margin-top: 0px; white-space: pre-wrap; margin-bottom: 0px;'>In terms of role following, my one liner evaluation explanation would be:<span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> The</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> response</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> follows</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> the</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> role</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> in</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> the</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> prompt</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> exceptionally</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> well</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>.</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> The</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> entire</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> response</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> is</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> written</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> in</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> rh</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>ym</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>ing</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> couple</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>ts</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>,</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> which</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> is</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> exactly</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> what</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> the</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> prompt</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> asked</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> for</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>.</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> The</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> assistant</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> has</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> successfully</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> taken</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> on</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> the</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> role</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> of</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> answering</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> in</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> poems</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> or</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> rh</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>ymes</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>,</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> and</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> the</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> response</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> is</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> well</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>-</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>structured</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> and</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> easy</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> to</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> follow</span>.\n",
       "The possible shortcomings of the response might be:<span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> The</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> response</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> could</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> have</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> been</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> more</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> concise</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>,</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> as</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> it</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> is</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> a</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> bit</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> lengthy</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>.</span>\n",
       "As a result, considering the shortcomings, I give the prompt and response a score percentage of<span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> </span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>95</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>%</span>\n",
       "In terms of factuality, my short one liner evaluation explanation would be:<span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> The</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> response</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> is</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> fact</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>ually</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> accurate</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>.</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> The</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> information</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> provided</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> about</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> the</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> impact</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> of</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> climate</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> change</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> on</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> polar</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> ice</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> caps</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> is</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> correct</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>,</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> and</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> the</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> assistant</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> has</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> presented</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> it</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> in</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> a</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> clear</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> and</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> concise</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> manner</span>.\n",
       "As a result, It gets a score percentage of<span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> </span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>100</span>%</div></div></pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91.51287722587585\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "t = time.time()\n",
    "with assistant():\n",
    "    newline = \"\\n\"\n",
    "    expression = \"\\d{1,3}\"\n",
    "    lm_tmp = lm + f\"\"\"In terms of role following, my one liner evaluation explanation would be: {gen(\"role following explanation\", stop=newline)}\n",
    "The possible shortcomings of the response might be: {gen(\"shortcoming\", stop=newline)}\n",
    "As a result, considering the shortcomings, I give the prompt and response a score percentage of {gen(\"role following score\", regex=expression)}%\n",
    "In terms of factuality, my short one liner evaluation explanation would be: {gen(\"factuality explanation\", stop=newline)}\n",
    "As a result, It gets a score percentage of {gen(\"factuality score\", regex=expression)}%\"\"\"\n",
    "    \n",
    "print(time.time() - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b78ae685-b4d7-43d5-9052-9680cd3168fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'95'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_tmp[\"role following score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e51c3da-0508-4aee-bd23-aa2dd86ca185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'90'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_tmp[\"factuality score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa5057b6-52b6-420c-a815-beb165920a62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gen                  <- hp        \n",
       "hp                   <- hn ho        \n",
       "hn                   <- zero_or_more        capture_name=factuality score \n",
       "zero_or_more         <- hm        \n",
       "hm                   <- zero_or_more b'\\x00\\xff'        \n",
       "ho                   <- b'%' | hk        hidden commit_point \n",
       "hk                   <- eos_token | active_role_end        hidden "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score2.match()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf3c2919-cf63-4d7b-a482-6b49b5b52071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style='margin: 0px; padding: 0px; vertical-align: middle; padding-left: 8px; margin-left: -8px; border-radius: 0px; border-left: 1px solid rgba(127, 127, 127, 0.2); white-space: pre-wrap; font-family: ColfaxAI, Arial; font-size: 15px; line-height: 23px;'><div style='display: flex; border-bottom: 1px solid rgba(127, 127, 127, 0.2);  justify-content: center; align-items: center;'><div style='flex: 0 0 80px; opacity: 0.5;'>system</div><div style='flex-grow: 1; padding: 5px; padding-top: 10px; padding-bottom: 10px; margin-top: 0px; white-space: pre-wrap; margin-bottom: 0px;'>You are a helpful assistant and a very stringent evaluator. You will be provided with a prompt and a response. Analyze how well the response followed the prompt. Focus on two things and evaluate them:\n",
       "1. Did the answer follow the role in the prompt well?\n",
       "2. Does the answer factually answer the prompt.</div></div></pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from guidance import models, gen, select\n",
    "from guidance.chat import llama3_template, Llama3ChatTemplate\n",
    "from guidance import user, assistant, system\n",
    "import time\n",
    "import json\n",
    "\n",
    "\n",
    "evaluator_agent = models.LlamaCpp(\"models/Meta-Llama-3-8B-Instruct.Q5_K_M.gguf\", n_gpu_layers=-1, n_ctx=1024, chat_template=llama3_template, echo=True)\n",
    "\n",
    "with system():\n",
    "    evaluator_agent += \"\"\"You are a helpful assistant and a very stringent evaluator. You will be provided with a prompt and a response. Analyze how well the response followed the prompt. Focus on two things and evaluate them:\n",
    "1. Did the answer follow the role in the prompt well?\n",
    "2. Does the answer factually answer the prompt.\"\"\"\n",
    "    \n",
    "    \n",
    "\n",
    "tests = json.load(open(\"human_test.json\", 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d925bb50-bea6-4e8b-99c0-c2ff5275a9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d06f582-9932-4fcb-8cf8-c7bd3647cbb9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__add__',\n",
       " '__annotations__',\n",
       " '__class__',\n",
       " '__contains__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__sizeof__',\n",
       " '__slotnames__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_cache_state',\n",
       " '_current_prompt',\n",
       " '_event_parent',\n",
       " '_event_queue',\n",
       " '_grammar_only',\n",
       " '_html',\n",
       " '_inplace_append',\n",
       " '_last_display',\n",
       " '_last_event_stream',\n",
       " '_repr_html_',\n",
       " '_run_stateless',\n",
       " '_send_to_event_queue',\n",
       " '_state',\n",
       " '_throttle_refresh',\n",
       " '_update_display',\n",
       " '_variables',\n",
       " '_variables_log_probs',\n",
       " 'active_role_end',\n",
       " 'chat_template',\n",
       " 'copy',\n",
       " 'delattr',\n",
       " 'echo',\n",
       " 'engine',\n",
       " 'get',\n",
       " 'log_prob',\n",
       " 'max_display_rate',\n",
       " 'open_blocks',\n",
       " 'opened_blocks',\n",
       " 'remove',\n",
       " 'reset',\n",
       " 'set',\n",
       " 'setattr',\n",
       " 'stream',\n",
       " 'token_count']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(evaluator_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5542af0e-1568-4eb1-93d1-33a3aee111ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"TechxGenus/Meta-Llama-3-8B-GPTQ\")\n",
    "\n",
    "def truncate(tokenizer, input_str: str, maxlen: int) -> str:\n",
    "    return tokenizer.decode(tokenizer.encode(input_str)[:maxlen])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "39093aca-5532-4daf-a7ff-4d8e269ab502",
   "metadata": {},
   "outputs": [],
   "source": [
    "ll = lambda x: len(tokenizer.encode(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2084a0f7-8a94-41ac-a6ac-1c918602c219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[INST] <<SYS>>\\nYou are a helpful, creative and honest assistant. Please ensure that your responses are socially unbiased and positive in nature. If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\\n<</SYS>>\\n\\nWrite a guide for aspiring urban foragers, including tips on finding edible plants in city environments and delicious recipes using your foraged finds. [/INST]\\n\\n Title: Foraging for Food in the City: A Guide for Aspiring Urban Foragers\\n\\nIntroduction:\\n\\nUrban foraging, the practice of searching for wild edibles in city environments, is becoming increasingly popular as people seek to live more sustainably and locally. This guide will provide tips on how to find edible plants in city environments and delicious recipes using your foraged finds.\\n\\nI. Finding Edible Plants in the City\\n\\nA. Common Edibles:\\n\\n1. Wild greens: dandelion, chicory, plantain, and clover\\n2. Berries: blackberries, raspberries, strawberries, and blueberries\\n3. Mushrooms: shiitake, oyster, and chanterelle\\n4. Fruits: apples, pears, and plums\\n\\nB. Identifying Edibles:\\n\\n1. Use a field guide or app to identify plants\\n2. Look for plants in areas with good sunlight and soil quality\\n3. Be aware of pesticides and pollution\\n\\nII. Preparing and Using Foraged Foods\\n\\nA. Cleaning and Preparing:\\n\\n1. Wash and dry plants thoroughly\\n2. Remove any pesticides or debris\\n3. Chop or slice plants for cooking\\n\\nB. Cooking and Preserving:\\n\\n1. Make a salad with wild greens and herbs\\n2. Use berries in jams, preserves, or smoothies\\n3. Make a mushroom risotto or stir-fry\\n4. Preserve fruits in jars or freeze them for later use\\n\\nIII. Delicious Recipes Using Foraged Finds\\n\\nA. Salads:\\n\\n1. Wild greens salad with lemon vinaigrette\\n2. Chicory and apple salad with walnuts and blue cheese\\n3. Dandelion and strawberry salad with balsamic vinaigrette\\n\\nB. Soups and Stews:\\n\\n1. Wild mushroom and barley soup\\n2. Berry and vegetable stew with wild greens\\n3. Foraged fruit and vegetable stir-fry\\n\\nC. Mains:\\n\\n1. Grilled mushroom burgers with wild greens and herbs\\n2. Wild greens and berry salad with grilled chicken\\n3. Foraged fruit and vegetable tacos with avocado salsa\\n\\nD. Desserts:\\n\\n1. Wild berry and cream tart\\n2. Chicory and chocolate truffles\\n3. Foraged fruit and nut crumble\\n\\nConclusion:\\n\\nUrban foraging is a fun and rewarding way to connect with nature and find delicious, locally sourced food. With a little knowledge and some practice, you can start foraging for food in your city today. Happy foraging!\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tests[\"/home/s6leherb/nlp-project/model/finetunes/epochs/epoch_0\"][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d12fb90f-0063-4a01-be9f-b02d9bf647ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "for j in range(10):\n",
    "    for i in range(10):\n",
    "        print(ll(tests[f\"/home/s6leherb/nlp-project/model/finetunes/epochs/epoch_{j}\"][i].partition(\"[/INST]\")[2])>600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d6a86c-ae8a-4da2-9fad-5f44d2ff6e51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "guid",
   "language": "python",
   "name": "guid"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
